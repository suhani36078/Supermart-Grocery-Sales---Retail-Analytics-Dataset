# -*- coding: utf-8 -*-
"""Project2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hhj_FTi21ANuOBXkooaO3Q109ILidg26

**PROJECT-2**
#Supermart Grocery Sales---Retail Sales Analytic
"""

#import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#load the dataset
data=pd.read_csv('/content/Supermart.csv')

data.head(10)

#dispplay rows
data.index

#display columns
data.columns

#display dimensions
data.shape

#display basic information
data.info()

#To clean the data
data.isnull().sum()

#Drop any missing values
data.dropna(inplace=True)
#check for duplicates
data.drop_duplicates(inplace=True)

#convert date columns
data['Date']=pd.to_datetime(data['Order Date'])

# Extract day, month, and year from 'Order Date'
data['Order Day'] = data['Date'].dt.day
data['Order Month'] = data['Date'].dt.month
data['Order Year'] = data['Date'].dt.year

data.describe()

#Sales distribution by category
plt.figure(figsize=(10, 6))
sns.boxplot(x='Category', y='Sales', data=data)
plt.title('Sales Distribution by Category')
plt.show()

plt.figure(figsize=(12, 6))
data.groupby('Order Date')['Sales'].sum().plot()
plt.title('Total Sales Over Time')
plt.show()

#Profit by Region
sns.boxplot(x="Region", y = "Profit" ,data=data,color="pink").set_title("Profit by Region")

"""East Region appears to have the highest number of extreme high profit outliers, reaching above 1100.

"""

#top product which has highest sales
plt.figure(figsize=(8, 6))
# Group by Category and sum the Sales
sales_by_category = data.groupby('Category')['Sales'].sum()

# Sort the sales in descending order
sales_by_category_sorted = sales_by_category.sort_values(ascending=False)

#Plot the Top product
sales_by_category_sorted.plot(kind='bar',color="green")
plt.title('Top Product')
plt.xlabel("Sales")
plt.xticks(rotation=45)
plt.show()

#FEATURE SELECTION
# # Drop irrelevant or target columns
# features = data.drop(columns=['Order ID', 'Customer Name', 'Order Date', 'Sales', 'Order Month'])

# # Target variable
# target = data['Sales']

# print(data)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Create a copy of data to avoid issues
encoded_data = data.copy()

# Encode all object columns using separate LabelEncoders
for col in encoded_data.select_dtypes(include='object').columns:
    le = LabelEncoder()
    encoded_data[col] = le.fit_transform(encoded_data[col])

# Drop unneeded columns
features = encoded_data.drop(columns=['Order ID', 'Customer Name', 'Order Date', 'Sales', 'Order Month','Date'])

# Define the target
target = encoded_data['Sales']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)

# Scale features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#Train a Machine Learning Model
model=LinearRegression()
model.fit(X_train,y_train)

#Make Predictions
y_pred=model.predict(X_test)

#Evaluate a Model
# Calculate MSE and R-squared
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f'Mean Squared Error: {mse}')
print(f'R-squared: {r2}')

#Actual vs Predicted Price
plt.figure(figsize=(10, 6))
plt.scatter(y_test,y_pred)
plt.xlabel('Actual Sales')
plt.ylabel('Predicted Sales')
plt.title('Actual vs Predicted Sales')
plt.show()

#FIND YEARLY SALES
Yearly_Sales = data.groupby('Order Year')['Sales'].sum()
plt.pie(Yearly_Sales, labels=Yearly_Sales.index,autopct='%1.1f%%')
plt.title('Sales by Year')
plt.show()